{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Making Chatbots!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Rule Based Chatbot (ELIZA)\n",
    "In this section, you will implement a rule-based Chatbot, ELIZA, using the provided eliza.py file. The eliza.py file contains the rules for the model to follow, you need to complete the code to utilize the file to implement a chat agent while saving the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eliza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Eliza model from eliza.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliza = eliza.Eliza()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and open the file to save chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Format the date and time to create the file name\n",
    "file_name = f\"ELIZA_CHAT_{now.strftime('%Y_%m_%d_%H_%M_%S')}.txt\"\n",
    "f = open(file_name, \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the regex for exit\n",
    "You need to define an appropriate regex expression that searches for the appropriate words such as 'bye' or 'exit' in the user input to recognize that the user wants to end the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_end(input_string):\n",
    "    pattern = re.compile(r'\\b(bye|exit|quit)\\b', re.IGNORECASE)\n",
    "    if pattern.search(input_string):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a chat loop\n",
    "In this part, you need to define a loop that asks for user input and prints the user response till the user wants to end the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT:  Hi there... how are you today?\n",
      "AGENT:  How do you feel about being good, how am you?\n",
      "AGENT:  Would you prefer it if I were not feeling good too?\n",
      "AGENT:  How long have you been feeling depressed?\n",
      "AGENT:  since a few years ago.\n",
      "AGENT:  You seem quite sure.\n",
      "AGENT:  You seem quite sure.\n",
      "AGENT:  Please consider whether you can answer your own question.\n",
      "AGENT:  Very interesting.\n",
      "AGENT:  I see.  And what does that tell you?\n",
      "AGENT:  Can you elaborate on that?\n",
      "AGENT:  How do you feel about being from india, so it makes sense that you love indian cuisine the most?\n",
      "AGENT:  When do you usually feel good about that?\n",
      "AGENT:  Why do you say that when im eating?\n",
      "AGENT:  Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"USER: \")\n",
    "    if is_end(user_input):\n",
    "        # Output the goodbye message, write the last inputs and outputs to the log and close the file\n",
    "        print(\"AGENT:  Goodbye!\")\n",
    "        f.write(f\"USER: {user_input}\\n\") # Log the user's last input\n",
    "        f.write(f\"AGENT: Goodbye!\\n\") # Log the agent's goodbye message\n",
    "        f.close()\n",
    "        break\n",
    "    response = eliza.respond(user_input)\n",
    "    print(\"AGENT: \", response)\n",
    "    f.write(f\"USER: {user_input}\\n\") # Log the user's input\n",
    "    f.write(f\"AGENT: {response}\\n\") # Log the agent's response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats, you are done with part 1. You now need to simply test out your model for 5 chat conversations (minimum 10 utterances in each conversation) and report the results of the human survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Corpus Based Chatbot\n",
    "\n",
    "In this section, you will implement a corpus-based chatbot using the given dialogues.csv corpus. As a part of this task, you will first load the dataset, compute the sentence embeddings for the corpus sentences using the SentenceTransformer Library and then utilize these embeddings for retrieving the most appropriate response.\n",
    "\n",
    "Note: This part will be slow to run on a CPU based environment (upto 5 minutes), however, it should be very fast on a Colab GPU environment (close to 5 seconds), because of the use of transformer architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: sentence_transformers in c:\\users\\sudha\\anaconda3\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.47.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from sentence_transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from sentence_transformers) (0.26.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from sentence_transformers) (10.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "Load the dialogues.csv file using the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>User</th>\n",
       "      <th>Agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>Was this a friend you were in love with, or ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>Where has she gone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>Oh was this something that happened because of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>Was this a friend you were in love with, or ju...</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>We no longer talk.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                               User  \\\n",
       "0  sentimental  I remember going to see the fireworks with my ...   \n",
       "1  sentimental                This was a best friend. I miss her.   \n",
       "2  sentimental                                 We no longer talk.   \n",
       "3  sentimental  Was this a friend you were in love with, or ju...   \n",
       "4  sentimental                                Where has she gone?   \n",
       "\n",
       "                                               Agent  \n",
       "0  Was this a friend you were in love with, or ju...  \n",
       "1                                Where has she gone?  \n",
       "2  Oh was this something that happened because of...  \n",
       "3                This was a best friend. I miss her.  \n",
       "4                                 We no longer talk.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dialogues.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the SentenceTransformer model\n",
    "docs: https://sbert.net/docs/sentence_transformer/usage/usage.html\n",
    "\n",
    "Load the ```all-MiniLM-L6-v2``` sentence transformer model for computing the contextual embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the sentence embeddings\n",
    "For the 'User' column of the dataset, compute the sentence embeddings using the sentence transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dialogues = data['User'].tolist()\n",
    "user_embeddings = model.encode(user_dialogues, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the agent response\n",
    "In the get_response() function, utilize the user_embeddings to retrieve the most similar instance from the data point using cosine similarity. For the selected data point, return the corresponding response in the 'Agent' column of the data as the agent's reponse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sudha\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sudha\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(user_input, data, model, user_embeddings):\n",
    "    # Convert the input of the user to its sentence embedding\n",
    "    input_embedding = model.encode(user_input, convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    cosine_scores = util.pytorch_cos_sim(input_embedding, user_embeddings)\n",
    "    \n",
    "    # Find the index of the highest cosine similarity using np.argmax.\n",
    "    best_match_idx = torch.argmax(cosine_scores).item()\n",
    "    \n",
    "    # Return the corresponding string for the 'Agent' column\n",
    "    return data['Agent'].iloc[best_match_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and open the file to save chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define and open the file to save chat history\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Format the date and time to create the file name\n",
    "file_name = f\"CORPUS_CHAT_{now.strftime('%Y_%m_%d_%H_%M_%S')}.txt\"\n",
    "f = open(file_name, \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a chat loop\n",
    "In this part, you need to define a loop that asks for user input and prints the user response till the user wants to end the chat. Utilize the same regex expression as before to identify when the user wants to end the chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT: Wow! That's exciting! Was it what you were looking for?\n",
      "AGENT: Are you going to a restaurant or making it yourself?\n",
      "AGENT: I have only been looking. Nothing in my price range yet\n",
      "AGENT: Divorce him\n",
      "AGENT: Divorce him\n",
      "AGENT: But I should have known better. I cry about it every day.\n",
      "AGENT: My grandma died 5 weeks ago. I am still sad.\n",
      "AGENT: i got payed , went shopping ate dinner, then my friend messaged me asking for his money .... i had totally forgot about this\n",
      "AGENT: She is the sweetest woman I have ever met\n",
      "AGENT: And beer.. There has to be beer.\n",
      "AGENT: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"USER: \")\n",
    "    if is_end(user_input):\n",
    "        # Output the goodbye message, write the last inputs and outputs to the log and close the file\n",
    "        print(\"AGENT: Goodbye!\")\n",
    "        f.write(f\"USER: {user_input}\\n\") # Log the user's last input\n",
    "        f.write(\"AGENT: Goodbye!\\n\") # Log the agent's goodbye message\n",
    "        f.close()\n",
    "        break\n",
    "    response = get_response(user_input, data, model, user_embeddings)\n",
    "    print(\"AGENT:\", response)\n",
    "    f.write(f\"USER: {user_input}\\n\") # Log the user's input\n",
    "    f.write(f\"AGENT: {response}\\n\") # Log the agent's response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats, you are done with part 2. You now need to simply test out your model for 5 chat conversations (minimum 10 utterances in each conversation) and report the results of the human survey."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
